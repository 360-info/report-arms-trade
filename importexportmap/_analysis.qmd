---
title: "Arms trade: global map"
subtitle: "Transfers between countries"
author: "James Goldie, 360info"
date: "2022-07-28"
code-fold: true
theme: style/article.scss
---

```{r}
library(tidyverse)
library(sf)
library(lubridate)
library(countrycode)
library(cshapes)
library(skimr)
library(here)
```

I've downloaded SIPRI import/export TIV tables for each exporter (current as of 2022-07-28) to the `data/trademap-raw` folder.

Let's tidy up this data.

```{r}
#| label: import-fns

# read_tidy_single_exporter: read a single exporter csv in, then
# tidy up and lengthen it, ready to be merged
read_tidy_single_exporter <- function(path) {
  read_csv(path, skip = 10) %>%
    rename("recipient" = "...1") %>%
    filter(!is.na(recipient)) %>%
    # (years that are all empty read in as logical, not numeric. drop 'em)
    select(recipient, where(is.numeric)) %>%
    pivot_longer(cols = -recipient, names_to = "year", values_to = "count")
}

# extract_supplier: extract the country name from the first line of a sipri
# export tiv table csv file
extract_supplier <- function(path) {
  readLines(path, n = 1) %>%
    str_replace(coll('"TIV of arms exports from '), "") %>%
    str_replace(regex(', [:digit:]{4}\\-[:digit:]{4}",{1,}'), "")
}
```

```{r}
#| label: import

tibble(
  path = list.files(here("data", "trademap-raw"), pattern = glob2rx("*.csv"),
    full.names = TRUE)) %>%
  mutate(
    supplier = map_chr(path, extract_supplier),
    content = map(path, read_tidy_single_exporter)) %>%
  unnest(content) %>%
  select(-path) ->
all_data

# NOTE - do we want to create explicitly missing data?
```

Now we need some spatial context for these groups. In cases where it's a group within a country, SIPRI generally lists it as "Group name (country)*", so let's try to extract a country name from the parentheses.

```{r}
#| label: match-country-names

all_data %>%
  filter(supplier != "Total", recipient != "Total") %>%
  mutate(
    # first, try to get the country code directly
    supp_code_firstpass = countrycode(supplier, "country.name", "cown"),
    recp_code_firstpass = countrycode(recipient, "country.name", "cown"),
    # now, let's extract the parentheses
    supp_parenthesised =
      str_match(supplier, regex("(?<=\\().*?(?=\\))"))[,1],
    recp_parenthesised =
      str_match(recipient, regex("(?<=\\().*?(?=\\))"))[,1],
    # now try to get the country code again
    supp_code_secondpass =
      countrycode(supp_parenthesised, "country.name", "cown"),
    recp_code_secondpass =
      countrycode(recp_parenthesised, "country.name", "cown"),
    # and finally merge the attempts
    supplier_cown = coalesce(supp_code_firstpass, supp_code_secondpass),
    recipient_cown = coalesce(recp_code_firstpass, recp_code_secondpass)) %>%
  select(supplier, recipient, year, count, ends_with("cown")) ->
matched_countries
```

Let's see how many groups we successfully matched to a country with this process:

```{r}
#| label: skim-country-matches

matched_countries %>%
  filter(is.na(supplier_cown)) %>%
  select(supplier) %>%
  table()

matched_countries %>%
  filter(is.na(recipient_cown)) %>%
  select(recipient) %>%
  table()
```

Some of these, like the EU, UN, NATO, OSCE, RSS and AU, are groups that don't necessarily have a physical domain. Nor do "Unknown recipient(s)" (although "Unknown rebel group*" potentially could, depending on the context).

Some we can fix up manually:

- Western Sahara
- Palestine
- Hamas (Palestine)
- Biafra
- Katanga
- Micronesia
- Serbia

Now, let's get the geometry for these countries. [The `cshapes` package](https://icr.ethz.ch/data/cshapes) keeps historical country boundaries. This is really handy, since our arms trade data goes back to 1950, and countries have shifted over time.

The `cshapes` boundaries are structured as an `sf` object with one row for each country and period. For example, the US has three distinct sets of boundaries over its history (1886 to 1959, 1959, and 1959 to 2019), so the US has three rows in the dataset.

Let's split the data up into before and after 2019:

```{r}
#| label: split-historical-current

matched_countries %>%
  filter(year <= 2019) ->
historical_transfers

matched_countries %>%
  filter(year > 2019) ->
current_transfers
```

Now we'll get historical country centroids from `cshapes` and merge them into our historical transfers data using the numerical Correlates of War code:

```{r}
#| label: merge-historical

sf::sf_use_s2(FALSE)

shapes_all_full <-
  cshp(useGW = FALSE, dependencies = TRUE) %>%
  st_centroid(of_largest_polygon = TRUE) %>%
  mutate(centre = st_coordinates(geometry)) %>%
  as_tibble() %>%
  mutate(lon = centre[, 1], lat = centre[, 2]) %>%
  select(cowcode, start, end, lon, lat)

# join twice: first by supplier, then by recipient
historical_transfers %>%
  mutate(transfer_date = ymd(paste0(year, "-01-01"))) %>%
  left_join(shapes_all_full, by = c("supplier_cown" = "cowcode")) %>%
  filter(transfer_date >= start, transfer_date < end) %>%
  select(-start, -end) %>%
  rename(supplier_lon = lon, supplier_lat = lat) %>%
  left_join(shapes_all_full, by = c("recipient_cown" = "cowcode")) %>%
  filter(transfer_date >= start, transfer_date < end) %>%
  select(-start, -end) %>%
  rename(recipient_lon = lon, recipient_lat = lat) ->
historical_transfer_centroids
```

For data since 2020, we'll need to assume current political boundaries. If we want to use another dataset for current boundaries, we'll likely need an ISO3 code rather than a COW code. But not all suppliers and recipients have one:

```{r}
#| label: check-cown-iso3

current_transfers %>%
  # we'll need iso3 codes for the modern countries
  mutate(
    supplier_iso3 = countrycode(supplier_cown, "cown", "iso3c"),
    recipient_iso3 = countrycode(recipient_cown, "cown", "iso3c")) %>%
  # show me countries that have a cown but not an iso3
  filter(
    (is.na(supplier_iso3) & (!is.na(supplier_cown))) |
    (is.na(recipient_iso3) & (!is.na(recipient_cown)))) %>%
  select(-year, -count) %>%
  distinct(supplier_cown, recipient_cown, .keep_all = TRUE) %>%
  print(n = Inf)
```

Instead, let's use the latest `cshapes` boundaries, which _should_ be current up to 2019 for most countries. We may need to fix a few up.

```{r}
#| label: merge-current

# we'll just use the most current (2019?) boundaries
shapes_all_full %>%
  group_by(cowcode) %>%
  slice_max(end) ->
latest_shapes

# join twice: first by supplier, then by recipient
current_transfers %>%
  mutate(transfer_date = ymd(paste0(year, "-01-01"))) %>%
  left_join(latest_shapes, by = c("supplier_cown" = "cowcode")) %>%
  rename(supplier_start = start, supplier_end = end) %>%
  rename(supplier_lon = lon, supplier_lat = lat) %>%
  left_join(latest_shapes, by = c("recipient_cown" = "cowcode")) %>%
  rename(recipient_start = start, recipient_end = end) %>%
  rename(recipient_lon = lon, recipient_lat = lat) ->
current_transfer_centroids
```

I'll just confirm that most of the merges are using 2019 boundaries:

```{r}
current_transfer_centroids %>%
  mutate(end_min = pmin(supplier_end, recipient_end)) %>%
  select(end_min, everything()) %>%
  filter(!is.na(end_min)) %>%
  arrange(end_min) %>%
  distinct(end_min, .keep_all = T) %>%
  print(n = Inf)
```

Looks like all but four country pairings have boundary dates (`end_min`) going up to the end of 2019. So we also need to manually review:

- South Vietnam
- Southern rebels (Yemen)*
- East Germany (GDR)
- Czechoslovakia

### Uniting historical and current trades

Let's join the two back up:

```{r}
current_transfer_centroids %>%
  select(-ends_with("start"), -ends_with("end")) %>%
  bind_rows(historical_transfer_centroids) %>%
  # finally, ditch the NA rows (no export)
  filter(!is.na(count)) %>%
  write_csv(here("data", "sipri-exports-processed.csv")) %>%
  write_csv(here("importexportmap", "sipri-exports-processed.csv")) %>%
  write_csv(here("data", "sipri-exports-processed.csv.gz")) ->
all_transfer_centroids

# geojson export: we need each row's geometry to be a line from supplier
# to recipient. let's pivot suppliers and recipients longer, then convert to
# sf and summarise to get the linestrings
all_transfer_centroids %>%
  rename(supplier_name = supplier, recipient_name = recipient) %>%
  mutate(
    transfer_id = 1:n()) %>%
  pivot_longer(
    c(starts_with("supplier"), starts_with("recipient")),
    names_to = c("role", ".value"), names_sep = "_") %>%
  filter(!is.na(lat), !is.na(lon)) %>%
  st_as_sf(coords = c("lon", "lat")) %>%
  group_by(transfer_id) %>%
  arrange(desc(role)) %>%     # supplier before recipient 
  summarise(
    year = year[1],
    supplier_name = name[1],
    recipient_name = name[2],
    supplier_name = name[1],
    recipient_name = name[2],
    count = count[1]) %>%
  mutate(count = as.integer(count)) ->
all_transfer_lines

st_write(
  all_transfer_lines,
  here("data", "sipri-exports-processed.geojson"),
  delete_dsn = TRUE)

# geojson compression?
```

As a final check, let's have a look at the annual totals:

```{r}
all_transfer_centroids %>%
  group_by(year) %>%
    summarise(count_all = sum(count, na.rm = TRUE)) %>%
    mutate(date = ymd(paste0(year, "-07-01"))) %>%
    {
      ggplot(.) +
      aes(x = date, y = count_all / 1000) +
      geom_line() +
      geom_point() +
      geom_smooth() +
      labs(x = NULL, y = "TIV in $B")
    }
```

This squares with the totals straight out of SIPRI's 